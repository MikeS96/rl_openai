{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episodic Mountain Car function appoximation and control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is intended to solve the Episodic Mountain car problem using Semi-gradient sarsa and Tile Coding.\n",
    "\n",
    "The description of the problem is given below:\n",
    "\n",
    "\"A car is on a one-dimensional track, positioned between two \"mountains\". The goal is to drive up the mountain on the right; however, the car's engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.\" \n",
    "\n",
    "<img src=\"./assets/car.png\" width=\"380\" />\n",
    "\n",
    "An extensive description and solution of the problem can be seen here [Section 10.1 Reinforment Learning an Introduction](http://www.incompleteideas.net/book/RLbook2018.pdf#page=267)\n",
    "\n",
    "Image and Text taken from Taken from [Official documentaiton Mountain car](https://gym.openai.com/envs/MountainCar-v0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tiles3 as tc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undestanding the Workflow of OpenAI\n",
    "\n",
    "The following variables are used at each timestep and they are returned by the Mountain Car environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **observation** (object): an environment-specific object representing your observation of the environment. For example, pixel data from a camera, joint angles and joint velocities of a robot, or the board state in a board game.\n",
    "- **reward** (float): amount of reward achieved by the previous action. The scale varies between environments, but the goal is always to increase your total reward.\n",
    "- **done** (boolean): whether it’s time to reset the environment again. Most (but not all) tasks are divided up into well-defined episodes, and done being True indicates the episode has terminated. (For example, perhaps the pole tipped too far, or you lost your last life.)\n",
    "- **info** (dict): diagnostic information useful for debugging. It can sometimes be useful for learning (for example, it might contain the raw probabilities behind the environment’s last state change). However, official evaluations of your agent are not allowed to use this for learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick recap, the diagram below explains the workflow of a Markov Decision Process (MDP)\n",
    "\n",
    "<img src=\"./assets/MDP.png\" width=\"380\" />\n",
    "\n",
    "Image taken from [Section 3.1 Reinforment Learning an Introduction](http://www.incompleteideas.net/book/RLbook2018.pdf#page=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Agent specifications\n",
    "\n",
    "Below are presented the main features of the environment and agent. Overall, the action space of the problem is discrete with three posible actions. The observations or state space is continuios, therefore it is necessary to use a function approximation technique to solve this challenge. The agent receives a reward of -1 at each timestep unless it reaches the goal. The episode ends if the agent reaches the goal or a specific number of iterations are done. Additionally, the agent will always start at a random position between $-0.6$ and $-0.4$ with zero velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: \n",
    "\n",
    "     Type:  Box(2)\n",
    "     Num    Observation               Min            Max\n",
    "     0      Car Position              -1.2           0.6\n",
    "     1      Car Velocity              -0.07          0.07\n",
    "         \n",
    "**Actions**:\n",
    "\n",
    "     Type: Discrete(3)\n",
    "     Num    Action\n",
    "     0      Accelerate to the Left\n",
    "     1      Don't accelerate\n",
    "     2      Accelerate to the Right\n",
    "\n",
    "     Note: This does not affect the amount of velocity affected by the gravitational pull acting on the car\n",
    "        \n",
    "**Reward**:\n",
    "\n",
    "     Reward of 0 is awarded if the agent reached the flag(position = 0.5) on top of the mountain\n",
    "     Reward of -1 is awarded if the position of the agent is less than 0.5\n",
    "        \n",
    "**Starting State**:\n",
    "\n",
    "     The position of the car is assigned a uniform random value in [-0.6 , -0.4]\n",
    "     The velocity of the car is always assigned to 0\n",
    "        \n",
    "**Episode Termination**:\n",
    "\n",
    "     The car position is more than 0.5\n",
    "     Episode length is greater than 200\n",
    "     \n",
    "For further information see [Github source code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/mountain_car.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell aims to show how to iterate with the action and observation space of the agent and extract relevant information from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Action Space is an object of type: Discrete(3)\n",
      "\n",
      "The shape of the action space is: 3\n",
      "\n",
      "The Environment Space is an object of type: Box(2,)\n",
      "\n",
      "The Shape of the dimension Space are: (2,)\n",
      "\n",
      "The High values in the observation space are [0.6  0.07], the low values are [-1.2  -0.07]\n",
      "\n",
      "The minimum and maximum car's position are: -1.2000000476837158, 0.6000000238418579\n",
      "\n",
      "The minimum and maximum car's velocity are: -0.07000000029802322, 0.07000000029802322\n",
      "\n",
      "The Observations at a given timestep are [-0.06817169 -0.06478962]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "observation = env.reset() \n",
    "\n",
    "# Object's type in the action Space\n",
    "print(\"The Action Space is an object of type: {0}\\n\".format(env.action_space))\n",
    "# Shape of the action Space\n",
    "print(\"The shape of the action space is: {0}\\n\".format(env.action_space.n))\n",
    "# Object's type in the Observation Space\n",
    "print(\"The Environment Space is an object of type: {0}\\n\".format(env.observation_space))\n",
    "# Shape of the observation space\n",
    "print(\"The Shape of the dimension Space are: {0}\\n\".format(env.observation_space.shape))\n",
    "# The high and low values in the observation space\n",
    "print(\"The High values in the observation space are {0}, the low values are {1}\\n\".format(\n",
    "    env.observation_space.high, env.observation_space.low))\n",
    "# Minimum and Maximum car position\n",
    "print(\"The minimum and maximum car's position are: {0}, {1}\\n\".format(\n",
    "    env.observation_space.low[0], env.observation_space.high[0]))\n",
    "# Minimum and Maximum car velocity\n",
    "print(\"The minimum and maximum car's velocity are: {0}, {1}\\n\".format(\n",
    "    env.observation_space.low[1], env.observation_space.high[1]))\n",
    "# Example of observation\n",
    "print(\"The Observations at a given timestep are {0}\\n\".format(env.observation_space.sample()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tile Coding Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a complete explanation about what is tile coding and how it works, see [Section 9.5.4 of Reinforment Learning an Introduction](http://www.incompleteideas.net/book/RLbook2018.pdf#page=239). Overall, this is a way to create features that can both provide good generalization and discrimination for value function approximation. Tile coding consists of multiple overlapping tiling, where each tiling is a partitioning of the space into tiles.\n",
    "\n",
    "<img src=\"./assets/tilecoding.png\" width=\"640\" />\n",
    "\n",
    "**Note**: Tile coding can be only be used with 2d observation spaces.\n",
    "\n",
    "This technique is implemented using Tiles3, which is a python library written by Richard S. Sutton. For the full documentation see [Tiles3 documentation](http://incompleteideas.net/tiles/tiles3.html)\n",
    "\n",
    "Image taken from [Section 9.5.4 of Reinforment Learning an Introduction](http://www.incompleteideas.net/book/RLbook2018.pdf#page=239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile Coding Class\n",
    "class MountainCarTileCoder:\n",
    "    def __init__(self, iht_size=4096, num_tilings=8, num_tiles=8):\n",
    "        \"\"\"\n",
    "        Initializes the MountainCar Tile Coder\n",
    "        Initializers:\n",
    "        iht_size -- int, the size of the index hash table, typically a power of 2\n",
    "        num_tilings -- int, the number of tilings\n",
    "        num_tiles -- int, the number of tiles. Here both the width and height of the\n",
    "                     tile coder are the same\n",
    "        Class Variables:\n",
    "        self.iht -- tc.IHT, the index hash table that the tile coder will use\n",
    "        self.num_tilings -- int, the number of tilings the tile coder will use\n",
    "        self.num_tiles -- int, the number of tiles the tile coder will use\n",
    "        \"\"\"\n",
    "        self.iht = tc.IHT(iht_size)\n",
    "        self.num_tilings = num_tilings\n",
    "        self.num_tiles = num_tiles\n",
    "    \n",
    "    def get_tiles(self, position, velocity):\n",
    "        \"\"\"\n",
    "        Takes in a position and velocity from the mountaincar environment\n",
    "        and returns a numpy array of active tiles.\n",
    "        \n",
    "        Arguments:\n",
    "        position -- float, the position of the agent between -1.2 and 0.5\n",
    "        velocity -- float, the velocity of the agent between -0.07 and 0.07\n",
    "        returns:\n",
    "        tiles - np.array, active tiles\n",
    "        \"\"\"\n",
    "        # Set the max and min of position and velocity to scale the input\n",
    "        # The max position is set to 0.5 as this is the position to end the experiment\n",
    "        POSITION_MIN = -1.2\n",
    "        POSITION_MAX = 0.5\n",
    "        VELOCITY_MIN = -0.07\n",
    "        VELOCITY_MAX = 0.07\n",
    "        \n",
    "        # Scale position and velocity by multiplying the inputs of each by their scale\n",
    "        position_scale = self.num_tiles / (POSITION_MAX - POSITION_MIN)\n",
    "        velocity_scale = self.num_tiles / (VELOCITY_MAX - VELOCITY_MIN)\n",
    "        \n",
    "        # Obtain active tiles for current position and velocity\n",
    "        tiles = tc.tiles(self.iht, self.num_tilings, [position * position_scale, \n",
    "                                                      velocity * velocity_scale])\n",
    "        \n",
    "        return np.array(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tiles obtained are: [0 1 2 3 4 5 6 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the TileCoder class\n",
    "mctc = MountainCarTileCoder(iht_size = 1024, num_tilings = 8, num_tiles = 8)\n",
    "tiles = mctc.get_tiles(position = -1.0, velocity = 0.01)\n",
    "# Tiles obtained at a random pos and vel\n",
    "print(\"The Tiles obtained are: {0}\\n\".format(tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Sarsa Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the Mountain Car problem, Value Function approximation and control will be used (Owing to the continuous state space). As a quick recap, Action-values can be computed using value function approximation giving the following equation.\n",
    "\n",
    "\\begin{equation} \n",
    "q_\\pi(s) \\approx \\hat{q}(s, a, w) \\doteq w^T x(s,a)\n",
    "\\end{equation}\n",
    "\n",
    "Where $w$ are a set of weights and $x(s,a)$ are the features vector which are computed using tile coding.\n",
    "\n",
    "Using the Tile coder implemented above it is possible to compute the action-values $\\hat{q}(s, a, w)$ and solve this RL task. \n",
    "\n",
    "The equation to update the weights using the Sarsa algorithm is given below. Here, $\\nabla \\hat{q}(S_t, A_t, w)$ is the gradient of the action-values approximation but as $x(s,a)$ is a linear function, the gradient is one only for the active features.\n",
    "\n",
    "\\begin{equation} \n",
    "w \\leftarrow w + \\alpha[R_{t+1} + \\gamma \\hat{q}(S_{t+1}, A_{t+1}, w)- \\hat{q}(S_t, A_t, w)]\\nabla \\hat{q}(S_t, A_t, w)\n",
    "\\end{equation}\n",
    "\n",
    "Additionally, the update \"Target\" is composed of the following terms:\n",
    "\n",
    "\\begin{equation} \n",
    "\\delta \\leftarrow R_{t+1} + \\gamma \\hat{q}(S_{t+1}, A_{t+1}, w)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation} \n",
    "w \\leftarrow w + \\alpha[\\delta - \\hat{q}(S_t, A_t, w)]\\nabla \\hat{q}(S_t, A_t, w)\n",
    "\\end{equation}\n",
    "\n",
    "The Pseudo-code implementation of this algorithm is given below.\n",
    "\n",
    "<img src=\"./assets/pseudocode.png\" width=\"480\" />\n",
    "\n",
    "\n",
    "For further details, see [Section 9.5.4 of Reinforment Learning an Introduction](http://www.incompleteideas.net/book/RLbook2018.pdf#page=266). Image taken from the last reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARSA\n",
    "class SarsaAgent():\n",
    "    \"\"\"\n",
    "    Initialization of Sarsa Agent. All values are set to None so they can\n",
    "    be initialized in the agent_init method.\n",
    "    \"\"\"\n",
    "    def __init__(self, agent_info={}):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\"\"\"\n",
    "        self.last_action = None\n",
    "        self.last_state = None\n",
    "        self.epsilon = None\n",
    "        self.gamma = None\n",
    "        self.iht_size = None\n",
    "        self.w = None\n",
    "        self.alpha = None\n",
    "        self.num_tilings = None\n",
    "        self.num_tiles = None\n",
    "        self.mctc = None\n",
    "        self.initial_weights = None\n",
    "        self.num_actions = None\n",
    "        self.previous_tiles = None\n",
    "\n",
    "    def agent_init(self, agent_info={}):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\"\"\"\n",
    "        self.num_tilings = agent_info.get(\"num_tilings\", 8)\n",
    "        self.num_tiles = agent_info.get(\"num_tiles\", 8)\n",
    "        self.iht_size = agent_info.get(\"iht_size\", 4096)\n",
    "        self.epsilon = agent_info.get(\"epsilon\", 0.0)\n",
    "        self.gamma = agent_info.get(\"gamma\", 1.0)\n",
    "        self.alpha = agent_info.get(\"alpha\", 0.5) / self.num_tilings\n",
    "        self.initial_weights = agent_info.get(\"initial_weights\", 0.0)\n",
    "        self.num_actions = agent_info.get(\"num_actions\", 3)\n",
    "        \n",
    "        # Initialize self.w to three times the iht_size. Recall this is because\n",
    "        # we need to have one set of weights for each action (Stacked values).\n",
    "        self.w = np.ones((self.num_actions, self.iht_size)) * self.initial_weights\n",
    "        \n",
    "        # Initialize self.mctc to the mountaincar verions of the  tile coder created\n",
    "        self.mctc = MountainCarTileCoder(iht_size = self.iht_size, \n",
    "                                         num_tilings = self.num_tilings, \n",
    "                                         num_tiles = self.num_tiles)\n",
    "\n",
    "    def select_action(self, tiles):\n",
    "        \"\"\"\n",
    "        Selects an action using epsilon greedy\n",
    "        Args:\n",
    "        tiles - np.array, an array of active tiles\n",
    "        Returns:\n",
    "        (chosen_action, action_value) - (int, float), tuple of the chosen action\n",
    "                                        and it's value\n",
    "        \"\"\"\n",
    "        action_values = []\n",
    "        chosen_action = None\n",
    "        \n",
    "        # Obtain action values for all actions (sum through rows)\n",
    "        action_values = np.sum(self.w[:, tiles], axis = 1)\n",
    "        \n",
    "        # Epsilon Greedy action selecion\n",
    "        if np.random.random() < self.epsilon:\n",
    "            # Select random action among the three posible actions\n",
    "            chosen_action = np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            # Select the greedy action\n",
    "            chosen_action = argmax(action_values)\n",
    "        \n",
    "        return chosen_action, action_values[chosen_action]\n",
    "    \n",
    "    def agent_start(self, state):\n",
    "        \"\"\"The first method called when the experiment starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            state (Numpy array): the state observation from the\n",
    "                environment's env.reset() function.\n",
    "        Returns:\n",
    "            The first action the agent takes.\n",
    "        \"\"\"\n",
    "        # Current state\n",
    "        position, velocity = state\n",
    "        \n",
    "        # Obtain tiles activated at state cero\n",
    "        active_tiles = self.mctc.get_tiles(position = position, velocity = velocity)\n",
    "        # Select an action and obtain action values of the state\n",
    "        current_action, action_value = self.select_action(active_tiles)\n",
    "        \n",
    "        # Save action as last action\n",
    "        self.last_action = current_action\n",
    "        # Save tiles as previous tiles\n",
    "        self.previous_tiles = np.copy(active_tiles)\n",
    "        \n",
    "        return self.last_action\n",
    "\n",
    "    def agent_step(self, reward, state):\n",
    "        \"\"\"A step taken by the agent.\n",
    "        Args:\n",
    "            reward (float): the reward received for taking the last action taken\n",
    "            state (Numpy array): the state observation from the\n",
    "                environment's step based, where the agent ended up after the\n",
    "                last step\n",
    "        Returns:\n",
    "            The action the agent is taking.\n",
    "        \"\"\"\n",
    "        # Current state\n",
    "        position, velocity = state\n",
    "\n",
    "        # Compute current tiles\n",
    "        active_tiles = self.mctc.get_tiles(position = position, velocity = velocity)\n",
    "        # Obtain new action and action value before updating actition values\n",
    "        current_action, action_value = self.select_action(active_tiles)\n",
    "        \n",
    "        # Update the Sarsa Target (delta)\n",
    "        target = reward + (self.gamma * action_value)\n",
    "        \n",
    "        # Compute last action values to update weights\n",
    "        last_action_val = np.sum(self.w[self.last_action][self.previous_tiles]) \n",
    "        \n",
    "        # As we are using tile coding, which is a variant of linear function approximation\n",
    "        # The gradient of the active tiles are one, otherwise cero.\n",
    "        grad = 1\n",
    "        self.w[self.last_action][self.previous_tiles] = self.w[self.last_action][self.previous_tiles] + \\\n",
    "            self.alpha * (target - last_action_val) * grad\n",
    "                \n",
    "        self.last_action = current_action\n",
    "        self.previous_tiles = np.copy(active_tiles)\n",
    "        return self.last_action\n",
    "\n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the\n",
    "                terminal state.\n",
    "        \"\"\"\n",
    "\n",
    "        # There is no action_value used here because this is the end\n",
    "        # of the episode.\n",
    "        \n",
    "        # Compute delta\n",
    "        target = reward \n",
    "        # Compute last action value\n",
    "        last_action_val = np.sum(self.w[self.last_action][self.previous_tiles])\n",
    "        grad = 1\n",
    "        # Update weights\n",
    "        self.w[self.last_action][self.previous_tiles] = self.w[self.last_action][self.previous_tiles] + \\\n",
    "            self.alpha * (target - last_action_val) * grad\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment\n",
    "\n",
    "The following lines solves the Mountain Car problem and plot the average reward obtained over episodes and steps taken to solve the challenge at a specific episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Test Sarsa Agent \n",
    "num_runs = 10\n",
    "num_episodes = 30\n",
    "agent_info_options = {\"num_tilings\": 8, \"num_tiles\": 8, \"iht_size\": 4096,\n",
    "                      \"epsilon\": 0.0, \"gamma\": 1.0, \"alpha\": 0.5,\n",
    "                      \"initial_weights\": 0.0, \"num_actions\": 3}\n",
    "\n",
    "# Variable to store the amount of steps taken to solve the challeng\n",
    "all_steps = []\n",
    "# Variable to save the rewards in an episode\n",
    "all_rewards = []\n",
    "\n",
    "# Agent\n",
    "agent = SarsaAgent(agent_info_options)\n",
    "\n",
    "# Environment\n",
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "# Maximum number of possible iterations (default was 200)\n",
    "env._max_episode_steps = 10000\n",
    "\n",
    "# Number of runs are the times the experiment will start again (a.k.a episode)\n",
    "for n_runs in tqdm(range(num_runs)):\n",
    "    \n",
    "    # Resets environment\n",
    "    observation = env.reset()\n",
    "    # Reset agent\n",
    "    agent.agent_init(agent_info_options)\n",
    "    # Generate last state and action in the agent\n",
    "    last_action = agent.agent_start(observation)\n",
    "    # Steps taken at each episode to solve the challenge\n",
    "    steps_per_episode = []\n",
    "    rewards_per_episode = []\n",
    "        \n",
    "    # Times the environment will start again without resetting the agent\n",
    "    for t in range(num_episodes):\n",
    "        # Store number of steps taken to solve experiment\n",
    "        n_steps = 0\n",
    "        rewards = 0\n",
    "        # Reset done flag\n",
    "        done = False\n",
    "        # Reset environment\n",
    "        observation = env.reset()\n",
    "        # Run until the experiment is over\n",
    "        while not done:\n",
    "\n",
    "            # Take a step with the environment\n",
    "            observation, reward, done, info = env.step(last_action)\n",
    "            \n",
    "            # Number of steps the agent take to solve the challenge\n",
    "            n_steps += 1\n",
    "            # Accumulate reward\n",
    "            rewards += reward\n",
    "\n",
    "            # If the goal has been reached stop\n",
    "            if done:\n",
    "                # Last step with the agent\n",
    "                agent.agent_end(reward)\n",
    "                \n",
    "            else:\n",
    "                # Take a step with the agent\n",
    "                last_action = agent.agent_step(reward, observation)\n",
    "                \n",
    "        # Save the amount of steps needed to complete the experiment \n",
    "        # Without rebooting the agent\n",
    "        steps_per_episode.append(n_steps)\n",
    "        # Save the amount of award obtained at each episode\n",
    "        rewards_per_episode.append(rewards)\n",
    "        \n",
    "    # Save the list of steeps needed to finish the experiment \n",
    "    # in all the Episodes\n",
    "    all_steps.append(np.array(steps_per_episode))\n",
    "    # Awards obtained in every episode\n",
    "    all_rewards.append(np.array(rewards_per_episode))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Minimum number of iterations used to solve the experiment were: 3042\n",
      "\n",
      "The Maximum number of iterations used to solve the experiment were: 151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_average = np.mean(np.array(all_steps), axis=0)\n",
    "plt.plot(steps_average, label = 'Steps')\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Iterations\",rotation=0, labelpad=40)\n",
    "plt.xlim(-0.2, num_episodes)\n",
    "plt.ylim(steps_average.min(), steps_average.max())\n",
    "plt.title(\"Average iterations to solve the experiment over runs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"The Minimum number of iterations used to solve the experiment were: {0}\\n\".format(np.array(all_steps).max()))\n",
    "print(\"The Maximum number of iterations used to solve the experiment were: {0}\\n\".format(np.array(all_steps).min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best reward obtained solving the experiment was: -151.0\n",
      "\n",
      "The Wordt reward obtained solving the experiment was: -3042.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rewards_average = np.mean(all_rewards, axis=0)\n",
    "plt.plot(rewards_average, label = 'Average Reward')\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Sum of\\n rewards\\n during\\n episode\" ,rotation=0, labelpad=40)\n",
    "plt.xlim(-0.2, num_episodes)\n",
    "plt.ylim(rewards_average.min(), rewards_average.max())\n",
    "plt.title(\"Average iterations to solve the experiment over runs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"The best reward obtained solving the experiment was: {0}\\n\".format(np.array(all_rewards).max()))\n",
    "print(\"The Wordt reward obtained solving the experiment was: {0}\\n\".format(np.array(all_rewards).min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the last trained Agent \n",
    "\n",
    "This lines shows in a video the performance of the last trained agent and save a video with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 13/1000 [00:00<00:08, 120.88it/s]\u001b[A\n",
      "  3%|▎         | 26/1000 [00:00<00:08, 121.69it/s]\u001b[A\n",
      "  4%|▍         | 40/1000 [00:00<00:07, 125.46it/s]\u001b[A\n",
      "  5%|▌         | 53/1000 [00:00<00:07, 125.99it/s]\u001b[A\n",
      "  7%|▋         | 67/1000 [00:00<00:07, 127.33it/s]\u001b[A\n",
      "  8%|▊         | 81/1000 [00:00<00:07, 129.40it/s]\u001b[A\n",
      " 10%|▉         | 95/1000 [00:00<00:06, 130.08it/s]\u001b[A\n",
      " 11%|█         | 108/1000 [00:00<00:06, 129.70it/s]\u001b[A\n",
      " 12%|█▏        | 122/1000 [00:00<00:06, 130.58it/s]\u001b[A\n",
      " 14%|█▎        | 135/1000 [00:01<00:06, 128.63it/s]\u001b[A\n",
      " 16%|█▌        | 160/1000 [00:01<00:06, 126.99it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 161 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Sarsa Agent \n",
    "num_runs = 1\n",
    "num_episodes = 1000\n",
    "\n",
    "# Environment\n",
    "env_to_wrap = gym.make('MountainCar-v0')\n",
    "# Maximum number of possible iterations (default was 200)\n",
    "env_to_wrap._max_episode_steps = 1500\n",
    "env = Monitor(env_to_wrap, \"./video\", video_callable=lambda episode_id: True, force=True)\n",
    "\n",
    "\n",
    "# Number of runs are the times the experiment will start again (a.k.a episode)\n",
    "for n_runs in tqdm(range(num_runs)):\n",
    "    \n",
    "    # Resets environment\n",
    "    observation = env.reset()\n",
    "    # Generate last state and action in the agent\n",
    "    last_action = agent.agent_start(observation)\n",
    "        \n",
    "    # Times the environment will start again without resetting the agent\n",
    "    for t in tqdm(range(num_episodes)):\n",
    "\n",
    "        # View environment\n",
    "        env.render()\n",
    "\n",
    "        # Take a step with the environment\n",
    "        observation, reward, done, info = env.step(last_action)\n",
    "\n",
    "        # If the goal has been reached stop\n",
    "        if done:\n",
    "            # Last step with the agent\n",
    "            agent.agent_end(reward)\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            # Take a step with the agent\n",
    "            last_action = agent.agent_step(reward, observation)\n",
    "\n",
    "\n",
    "env.close()\n",
    "env_to_wrap.close()\n",
    "\n",
    "print(\"Episode finished after {} timesteps\".format(t+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
